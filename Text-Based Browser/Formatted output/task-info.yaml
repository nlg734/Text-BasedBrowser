type: edu
custom_name: stage6
files:
- name: tests.py
  visible: false
  text: |
    from hstest.stage_test import StageTest
    from hstest.test_case import TestCase
    from hstest.check_result import CheckResult

    import os
    import shutil

    from colorama import Fore

    import sys
    if sys.platform.startswith("win"):
        import _locale
        # pylint: disable=protected-access
        _locale._getdefaultlocale = (lambda *args: ['en_US', 'utf8'])

    CheckResult.correct = lambda: CheckResult(True, '')
    CheckResult.wrong = lambda feedback: CheckResult(False, feedback)


    class TextBasedBrowserTest(StageTest):

        def generate(self):

            dir_for_files = os.path.join(os.curdir, 'tb_tabs')
            return [
                TestCase(
                    stdin='2.python-requests.org\nexit',
                    attach='requests',
                    args=[dir_for_files]
                ),
                TestCase(
                    stdin='en.wikipedia.org\nwiki\nexit',
                    attach='Wikipedia',
                    args=[dir_for_files]
                ),
                TestCase(
                    stdin='nytimescom\nexit',
                    args=[dir_for_files]
                ),
                TestCase(
                    stdin='bloombergcom\nexit',
                    args=[dir_for_files]
                ),
            ]

        def _check_files(self, path_for_tabs: str, right_word: str) -> bool:
            """
            Helper which checks that browser saves visited url in files and
            provides access to them.

            :param path_for_tabs: directory which must contain saved tabs
            :param right_word: Word-marker which must be in right tab
            :return: True, if right_words is present in saved tab
            """

            path, dirs, filenames = next(os.walk(path_for_tabs))

            for file in filenames:

                with open(os.path.join(path_for_tabs, file), 'r', encoding='utf-8') as tab:
                    content = tab.read()

                    if '</p>' not in content and '</script>' not in content:
                        if '</div>' not in content and right_word in content:
                            return True

            return False

        def check(self, reply, attach):

            # Incorrect URL
            if attach is None:
                if '<p>' in reply:
                    return CheckResult.wrong('You haven\'t checked was URL correct')
                else:
                    return CheckResult.correct()

            # Correct URL
            if isinstance(attach, str):
                right_word = attach

                path_for_tabs = os.path.join(os.curdir, 'tb_tabs')

                if not os.path.isdir(path_for_tabs):
                    return CheckResult.wrong("There are no directory for tabs")

                if not self._check_files(path_for_tabs, right_word):
                    return CheckResult.wrong('There are no correct saved tabs')

                shutil.rmtree(path_for_tabs)

                if not Fore.BLUE in reply:
                    return CheckResult.wrong('There are no blue refs in output')

                if '</p>' not in reply and '</div>' not in reply:
                    if right_word in reply:
                        return CheckResult.correct()

                return CheckResult.wrong('You haven\'t parsed result of request')


    TextBasedBrowserTest('browser.browser').run_tests()
  learner_created: false
- name: browser/browser.py
  visible: true
  text: |
    import sys
    import os
    import requests
    from bs4 import BeautifulSoup


    def check_link(webpage, fold):
        for file in os.listdir(os.fsencode(fold)):
            if os.fsdecode(file).startswith(webpage):
                return os.fsdecode(file)
        return webpage[::-1].find(".")


    def remove_tags(text):
        parsed_text = ""
        soup = BeautifulSoup(text, "html.parser")
        tags = ['p', 'a', 'ul', 'ol', 'li', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'title']
        tagged = soup.find_all(tags)
        for tag in tagged:
            parsed_text = parsed_text + tag.get_text() + "\n"
        return parsed_text



    def main(folder):
        history = []
        while True:
            link = input()
            if link == "exit":
                break
            if link == "back":
                if len(history) == 0:
                    continue
                history.pop()
                with open(history.pop()) as url:
                    print(url.read())
                    continue
            status = check_link(link, folder)
            if status == -1:
                print("Error: Incorrect URL")
            elif isinstance(status, int):
                filepath = folder + "\\" + link[:status] + ".txt"
                url = open(filepath, "w")
                if link.lower().startswith("http"):
                    page = requests.get(link)
                else:
                    page = requests.get("https://" + link)
                url.write(remove_tags(page.text))
                url.close()
                url = open(filepath)
                print(url.read())
                history.append(filepath)
                url.close()
            else:
                filepath = folder + "\\" + status + ".txt"
                url = open(filepath, "r")
                print(url.read())
                url.close()
                history.append(filepath)


    args = sys.argv
    if len(args) != 2:
        print("Please give a directory.")
    else:
        try:
            os.mkdir(args[1])
        except FileExistsError:
            pass
        main(args[1])
  learner_created: true
feedback_link: https://hyperskill.org/projects/79/stages/441/implement
status: Solved
record: -1
